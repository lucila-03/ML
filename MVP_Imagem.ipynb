{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfRBsm6njbVG/mgEz1abOv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucila-03/ML/blob/main/MVP_Imagem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1PEQEdZ9zm4"
      },
      "source": [
        "## 1. Definição do Problema *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nQYT7kVTXkU"
      },
      "source": [
        "### Classificador de imagens binária -Tartaruga x Pinguim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8txxRM4UCGB"
      },
      "source": [
        "Dataset do kaggle, separado em arquivos, é um problema de visão computacional para destinguir a imagem é uma tartaruga ou pinguim. O sistema deve indentificar e classificar a imagem conforme modelos de machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "FM86p08BWjzL"
      },
      "outputs": [],
      "source": [
        "# Importação dos pacotes\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sklearn.metrics as skm\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from IPython.display import Image, display\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ybokALgXsIB"
      },
      "source": [
        "#### Utilidades\n",
        "\n",
        "`plot_confusion_matrix` é uma função python que imprime uma matriz de confusão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "UjP-l-e1X-hz"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    Esta função imprime e plota a matriz de confusão.\n",
        "    A normalização pode ser aplicada definindo `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Matriz de confusão normalizada\")\n",
        "    else:\n",
        "        print('Matriz de confusão sem normalização')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('Label real')\n",
        "    plt.xlabel('Label predito')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRC-zf-NYQHh"
      },
      "source": [
        "### 2. Carga de Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "ae6j7TiUYtfl"
      },
      "outputs": [],
      "source": [
        "train_dir = 'ML/train'\n",
        "val_dir = 'ML/valid/valid'\n",
        "test_dir = 'ML/test'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Definação do tamanho do batch e as dimensões das imagens"
      ],
      "metadata": {
        "id": "dlm99xmreM60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "num_classes = 2"
      ],
      "metadata": {
        "id": "7YV1NbfeIBjl"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Definação dos caminhos para os dados de treinamento e teste"
      ],
      "metadata": {
        "id": "9Q4spaTejmOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definação do tamanho do batch e as dimensões das imagens"
      ],
      "metadata": {
        "id": "UdeHa5UmWLHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "num_classes = 2"
      ],
      "metadata": {
        "id": "QSVg2PhJjstL"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99fc3e89"
      },
      "source": [
        "Preparação dos dados"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Criação dos data generators\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(img_height, img_width),\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical') #training set\n",
        "\n",
        "val_generator = test_datagen.flow_from_directory(val_dir,\n",
        "                                                target_size=(img_height, img_width),\n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                target_size=(img_height, img_width),\n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "t5R0gKaLkk-K",
        "outputId": "f0a70787-4494-466e-89f6-a5675384c392"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-c74445c7d3ea>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Criação dos data generators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m train_generator = train_datagen.flow_from_directory(train_dir,\n\u001b[0m\u001b[1;32m     12\u001b[0m                                                     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1646\u001b[0m                 \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \"\"\"\n\u001b[0;32m-> 1648\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1649\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ML/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyzbpdxYas-3"
      },
      "source": [
        "Agara vamos mover todos os arquivos imagem de carros e SUVs para pastas principais train e valid (Treino e validação)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04y4CyRdbJPn"
      },
      "source": [
        "Faço uma listagem dos arquivos que estão nas pastas train e valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNzF4qx5bEaV"
      },
      "outputs": [],
      "source": [
        "#Lista 20 imagens aleatorias de cada diretorio de treino e validação\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "diretorio_Pinguim = './mvp/train/Pinguim'\n",
        "diretorio_Tartaruga = './mvp/train/Tartaruga'\n",
        "diretorio_valid = './mvp/train/valid'\n",
        "num_amostras = 5\n",
        "\n",
        "print(f\"Amostras das imagens do diretório '{diretorio_train/diretorio_Pinguim}':\")\n",
        "print(f\"Amostras das imagens do diretório '{diretorio_train/diretorio_Tartaruga}':\")\n",
        "print(f\"Amostras das imagens do diretório '{diretorio_valid}':\")\n",
        "for imagem in imagens_amostra_valid:\n",
        "    print(imagem)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzhdE7shbYlj"
      },
      "source": [
        "#### Verificando a quantidade de imagens das duas classes no diretorio de treino e validação\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVXGhQ7Pbudr"
      },
      "outputs": [],
      "source": [
        "#verificando as quantidade de imagens de treino e de validação\n",
        "import os\n",
        "\n",
        "diretorio_base = './mvp'\n",
        "\n",
        "def contar_imagens(diretorio):\n",
        "    total_imagens = 0\n",
        "    for raiz, diretorios, arquivos in os.walk(diretorio):\n",
        "        for arquivo in arquivos:\n",
        "            if arquivo.lower().endswith(('.jpeg', '.jpg')):\n",
        "                total_imagens += 1\n",
        "    return total_imagens\n",
        "\n",
        "# Percorrer os diretórios em ./mvp\n",
        "for diretorio in os.listdir(diretorio_base):\n",
        "    diretorio_path = os.path.join(diretorio_base, diretorio)\n",
        "    if os.path.isdir(diretorio_path):\n",
        "        total = contar_imagens(diretorio_path)\n",
        "        print(f\"Total de imagens em {diretorio}: {total}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9mK2_jWcV4W"
      },
      "source": [
        "Criando dataframes com as informações das imagens para train e valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cC6TcPjcwDO"
      },
      "outputs": [],
      "source": [
        "#Criando o Dataframe com as imagens de treino e teste\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "diretorio_train = './mvp/train'\n",
        "diretorio_valid = './mvp/valid'\n",
        "\n",
        "def criar_dataframe(diretorio):\n",
        "    dados = []\n",
        "    for raiz, diretorios, arquivos in os.walk(diretorio):\n",
        "        for nome_arquivo in arquivos:\n",
        "            if nome_arquivo.lower().endswith(('.jpeg', '.jpg')):\n",
        "                caminho_imagem = os.path.join(raiz, nome_arquivo)\n",
        "                dados.append({'Diretório': raiz, 'Imagem': nome_arquivo})\n",
        "    return pd.DataFrame(dados)\n",
        "\n",
        "df_train = criar_dataframe(diretorio_train)\n",
        "df_valid = criar_dataframe(diretorio_valid)\n",
        "\n",
        "print(\"Dataframe com as imagens do diretório 'train':\")\n",
        "display(df_train)\n",
        "\n",
        "print(\"\\nDataframe com as imagens do diretório 'valid':\")\n",
        "display(df_valid)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMSNGFkRdXhc"
      },
      "source": [
        "Criando os atributos necessários para desenvolver o trabalho"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB1J2y_QdOAy"
      },
      "outputs": [],
      "source": [
        "#Criando os Atributos de Largura, Altura, Imagem, Canais, Classe\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "diretorio_train = './mvp/train'\n",
        "diretorio_valid = './mvp/valid'\n",
        "\n",
        "dados_imagens_train = []\n",
        "dados_imagens_valid = []\n",
        "\n",
        "def processar_imagens(diretorio, dados_imagens):\n",
        "    for raiz, diretorios, arquivos in os.walk(diretorio):\n",
        "        for arquivo in arquivos:\n",
        "            if arquivo.lower().endswith(('.jpeg', '.jpg')):\n",
        "                caminho_arquivo = os.path.join(raiz, arquivo)\n",
        "                with Image.open(caminho_arquivo) as img:\n",
        "                    largura, altura = img.size\n",
        "                    canais = img.mode\n",
        "                    classe = 'Car' if 'car' in arquivo.lower() else 'Truck'\n",
        "                    dados_imagens.append({'Imagem': arquivo, 'Largura': largura, 'Altura': altura, 'Canais': canais, 'Classe': classe})\n",
        "\n",
        "processar_imagens(diretorio_train, dados_imagens_train)\n",
        "processar_imagens(diretorio_valid, dados_imagens_valid)\n",
        "\n",
        "df_train = pd.DataFrame(dados_imagens_train)\n",
        "df_valid = pd.DataFrame(dados_imagens_valid)\n",
        "\n",
        "print('DataFrames com os campos adicionados')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3qaxPdXd4N0"
      },
      "source": [
        "Visualização dos datasets com os atributos criados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rk6e3REKeA-O"
      },
      "outputs": [],
      "source": [
        "print(\"Dataframe com as imagens do diretório de treinamento:\")\n",
        "display(df_train)\n",
        "\n",
        "print(\"\\nDataframe com as imagens do diretório de validação:\")\n",
        "display(df_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq528Xr1eRzN"
      },
      "source": [
        "Plotando um gráfico de barras empilhado com o numero de imagens por classe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afx72tGNeg_y"
      },
      "outputs": [],
      "source": [
        "# Contagem das classes\n",
        "contagem_classes_train = df_train['Classe'].value_counts()\n",
        "contagem_classes_valid = df_valid['Classe'].value_counts()\n",
        "\n",
        "# Plotagem do gráfico de barras\n",
        "fig, ax = plt.subplots()\n",
        "bar_plot_train = contagem_classes_train.plot(kind='bar', ax=ax, color='blue', label='Train')\n",
        "bar_plot_valid = contagem_classes_valid.plot(kind='bar', ax=ax, color='orange', label='Valid')\n",
        "\n",
        "# Configurações do gráfico\n",
        "ax.set_title('Cars vs Trucks - Dados Disponíveis')\n",
        "ax.set_xlabel('Classe')\n",
        "ax.set_ylabel('Contagem')\n",
        "\n",
        "# Configuração da legenda\n",
        "ax.legend()\n",
        "\n",
        "# Exibição do gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzBLcAx2etsZ"
      },
      "source": [
        "Visualizando algumas imagens do conjunto de dados de treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "th6tR-w5evbR"
      },
      "outputs": [],
      "source": [
        "\n",
        "#setando o diretorio onde se encontram as imagens\n",
        "diretorio_train = './mvp/train'\n",
        "#Setando o numero de imagens  serem exibidas\n",
        "num_imagens = 20\n",
        "#determinando o tamanho da imagem\n",
        "tamanho_imagem = (128, 128)\n",
        "\n",
        "# Selecionar aleatoriamente 20 índices de imagens do df_train\n",
        "indices_aleatorios = random.sample(range(len(df_train)), num_imagens)\n",
        "\n",
        "# Configurar a figura para exibir as imagens\n",
        "fig, axs = plt.subplots(4, 5, figsize=(12, 8))\n",
        "fig.subplots_adjust(hspace=0.4)\n",
        "\n",
        "# Plotar as imagens selecionadas aleatoriamente\n",
        "for i, indice in enumerate(indices_aleatorios):\n",
        "    imagem = df_train.loc[indice, 'Imagem']\n",
        "    caminho_imagem = os.path.join(diretorio_train, imagem)\n",
        "    img = Image.open(caminho_imagem)\n",
        "    img = img.resize(tamanho_imagem)\n",
        "\n",
        "    linha = i // 5\n",
        "    coluna = i % 5\n",
        "\n",
        "    axs[linha, coluna].imshow(img)\n",
        "    axs[linha, coluna].set_title(df_train.loc[indice, 'Classe'])\n",
        "    axs[linha, coluna].axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb7Dav_LgpiQ"
      },
      "source": [
        "Divisão dos dados em treino e teste: 30% das imagens para teste e 70% para treinamento do modelo de deep learning. Importante lembrar que os conjuntos devem ser disjuntos, ou seja, não devem poussir nenhum elemento em comum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqxvxEqLgwC7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Definir os campos a serem usados para a separação\n",
        "features = ['Imagem', 'Classe']\n",
        "\n",
        "# Separar os conjuntos de treino e teste\n",
        "train, test = train_test_split(df_train[features], test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE4Sgi3Gg1vy"
      },
      "source": [
        "Visualizando a divisão dos dados de treino e de teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVr56E3Qg4E2"
      },
      "outputs": [],
      "source": [
        "# Exibir informações sobre os conjuntos de treino e teste\n",
        "print(\"Conjunto de Treino:\")\n",
        "display(train)\n",
        "print(\"\")\n",
        "\n",
        "print(\"Conjunto de Teste:\")\n",
        "display(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRVzoDLnhMIP"
      },
      "source": [
        "Vamos utilizaar uma técnica amplamente utilizada no campo de aprendizado de máquina e visão computacional para aumentar a diversidade e a quantidade de dados de treinamento, aplicando transformações às imagens existentes. A técnica utilizada é o data augmentation, sob demanda durante o treinamento do modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfr5ES0F0z8G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "diretorio_train = './mvp/train'\n",
        "diretorio_valid = './mvp/valid'\n",
        "target_size = (128, 128) # Dimensões desejadas das imagens (largura, altura)\n",
        "batch_size = 32  # Tamanho do lote de dados\n",
        "\n",
        "# Configurar o ImageDataGenerator com split de validação e parâmetros solicitados\n",
        "print('Configurando o ImageDataGenerator')\n",
        "train_datagen = ImageDataGenerator(validation_split=0.2,\n",
        "                             rescale=1.0/255,\n",
        "                             rotation_range=48,\n",
        "                             shear_range=0.2,\n",
        "                             zoom_range=0.2,\n",
        "                             horizontal_flip=True,\n",
        "                             fill_mode='nearest')\n",
        "\n",
        "print('---------------------------')\n",
        "\n",
        "print('Gerando dados teste')\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "print('---------------------------- ')\n",
        "# Gerar os dados de treino\n",
        "print('Gerando dados de treino')\n",
        "train_generator=train_datagen.flow_from_dataframe(\n",
        "    train ,diretorio_train,\n",
        "    target_size=(128,128),\n",
        "    batch_size=50,\n",
        "    class_mode='binary',\n",
        "    x_col='Imagem',\n",
        "    y_col='Classe',\n",
        "    subset='training' #training set\n",
        "    )\n",
        "\n",
        "print('---------------------------')\n",
        "\n",
        "\n",
        "# Gerar os dados de validação\n",
        "print('Gerando dados de validação')\n",
        "val_generator=train_datagen.flow_from_dataframe(\n",
        "    train ,diretorio_train,\n",
        "    target_size=(128,128),\n",
        "    batch_size=50,\n",
        "    class_mode='binary',\n",
        "    x_col='Imagem',\n",
        "    y_col='Classe',\n",
        "    subset='validation' #validation  set\n",
        "    )\n",
        "print('------------------------------')\n",
        "\n",
        "# Gerar os dados de teste\n",
        "\n",
        "print('Gerando dados de Teste')\n",
        "\n",
        "test_generator=train_datagen.flow_from_dataframe(\n",
        "    test ,diretorio_train,\n",
        "    target_size=(128,128),\n",
        "    batch_size=50,\n",
        "    class_mode='binary',\n",
        "    x_col='Imagem',\n",
        "    y_col='Classe',\n",
        "    subset='training') #teste\n",
        "\n",
        "print('------------------------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc4-RkGR1Lqe"
      },
      "source": [
        "Visualizando um exemplo do tratamento das imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSm0Hakm1X0X"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Pegando um registro do dataframe\n",
        "sample = df_train.sample(n=1)\n",
        "\n",
        "# Neste caso o tipo de classe é categorico, pois temos um exemplo com apenas uma classe\n",
        "sample_generator = train_datagen.flow_from_dataframe(\n",
        "    sample,\n",
        "    diretorio_train,\n",
        "    x_col='Imagem',\n",
        "    y_col='Classe',\n",
        "    target_size=(128,128),\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12, 9))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    for x_batch, y_batch in sample_generator:\n",
        "        Imagem = x_batch[0]\n",
        "        plt.imshow(Imagem)\n",
        "        plt.axis('Off')\n",
        "        break\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaB-U8ao2DW3"
      },
      "source": [
        "###Configuração de um modelo de deep learning usando uma rede neural convolucional (CNN) simples com a biblioteca Keras\n",
        "\n",
        "#### Definição da arquitetura do modelo\n",
        "\n",
        "Aqui é especificada uma `camada convolucional 2D` que possui 32 filtros, um tamanho de filtro de 3x3 que usa a função de ativação `ReLU`. O parâmetro `input_shape` define a forma das imagens de entrada para a rede. Na sequência são adicionadas camadas `max-pooling` com a mesma função de ativação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOaGueU52CFR"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Crie o modelo da CNN\n",
        "model = Sequential()\n",
        "\n",
        "# Adicione as camadas convolucionais\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten\n",
        "model.add(Flatten())\n",
        "\n",
        "# Adicione camadas densas\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Para um problema de classificação binária\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r00TvzF2x_I"
      },
      "source": [
        "###Treinamento do modelo de deep learning\n",
        "\n",
        "#### Compilação do modelo Keras com as configurações do treinamento\n",
        "\n",
        "`optimizer='adam'`: especifica o otimizador a ser usado durante o treinamento.\n",
        "\n",
        "`loss='binary_crossentropy'`: especifica a função de perda a ser usada durante o treinamento. Para problemas de classificação binária, onde a variável alvo tem apenas duas categorias, a perda binária de entropia cruzada é freqüentemente empregada.\n",
        "\n",
        "`metrics=['accuracy']`: especifica as métricas de avaliação a serem usadas durante o treinamento e o teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IVo4GwE31Sn"
      },
      "outputs": [],
      "source": [
        "# Compile o modelo\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56FhV_Fj34uR"
      },
      "source": [
        "O método fit() inicia o processo de treinamento do modelo usando o gerador de dados para o treinamento train_generator e o gerador de dados de validação val_generator.\n",
        "Criado uma função para guardar as métricas de treinamento e validação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbdAicto29T2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "# Criar um callback personalizado para salvar as métricas de treinamento e validação\n",
        "class MetricsCallback(Callback):\n",
        "    def __init__(self):\n",
        "        self.train_accuracy = []\n",
        "        self.val_accuracy = []\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.train_accuracy.append(logs['accuracy'])\n",
        "        self.val_accuracy.append(logs['val_accuracy'])\n",
        "        self.train_loss.append(logs['loss'])\n",
        "        self.val_loss.append(logs['val_loss'])\n",
        "\n",
        "# Criar uma instância do callback personalizado\n",
        "metrics_callback = MetricsCallback()\n",
        "\n",
        "# Definir número de épocas e steps por época\n",
        "num_epochs = 100\n",
        "steps_per_epoch = 58\n",
        "\n",
        "# Treinar o modelo usando o callback e os parâmetros definidos\n",
        "model.fit_generator(train_generator, validation_data=val_generator, epochs=num_epochs, steps_per_epoch=steps_per_epoch, callbacks=[metrics_callback])\n",
        "\n",
        "# Avaliar o modelo no conjunto de teste\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "# Obter as métricas do callback personalizado\n",
        "train_accuracy = metrics_callback.train_accuracy\n",
        "val_accuracy = metrics_callback.val_accuracy\n",
        "train_loss = metrics_callback.train_loss\n",
        "val_loss = metrics_callback.val_loss\n",
        "\n",
        "# Criar um array com o número de épocas\n",
        "epochs = range(1, len(train_accuracy) + 1)\n",
        "\n",
        "# Plotar a acurácia\n",
        "plt.plot(epochs, train_accuracy, 'bo-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy')\n",
        "plt.axhline(test_accuracy, color='g', linestyle='-', label='Test Accuracy')\n",
        "plt.title('Training, Validation, and Test Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotar a perda\n",
        "plt.plot(epochs, train_loss, 'bo-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
        "plt.axhline(test_loss, color='g', linestyle='-', label='Test Loss')\n",
        "plt.title('Training, Validation, and Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbOaQ90B72mJ"
      },
      "source": [
        "###Carregando o modelo\n",
        "\n",
        "Carregando o modelo salvo para ganho de tempo na correção."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzWDkOzBpan4"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "import keras\n",
        "\n",
        "# URL do modelo\n",
        "url_model = 'http://liessin.com.br/mvp/sprint2/trained_model.h5'\n",
        "\n",
        "# Caminho local para salvar o modelo\n",
        "local_path = 'trained_model.h5'\n",
        "\n",
        "# Baixar o modelo do URL e salvá-lo localmente\n",
        "response = requests.get(url_model)\n",
        "with open(local_path, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "# Carregar o modelo\n",
        "loaded_model = keras.models.load_model(local_path)\n",
        "print(\"Modelo carregado com sucesso.\",local_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi0di5Bpxmes"
      },
      "source": [
        "Inicialmente, a acurácia estava em 0,6136, o que significa que o modelo estava classificando corretamente cerca de 61% dos exemplos. No entanto, após o treinamento, a acurácia aumentou para 0,9560, indicando que o modelo melhorou e agora classifica corretamente cerca de 96% dos exemplos com dos dados de treino.\n",
        "\n",
        "Da mesma forma, a perda inicial era de 0,6373, e após o treinamento, a perda diminuiu para 0,1030. Uma perda menor indica que o modelo está fazendo previsões mais precisas e se ajustando melhor aos dados de treino.\n",
        "\n",
        "Portanto, podemos concluir que o treinamento do modelo CNN com 100 épocas foi eficaz, pois resultou em uma melhoria significativa na acurácia e uma redução na perda. Isso indica que o modelo foi capaz de aprender e se ajustar aos dados de treinamento, fornecendo previsões mais precisas.\n",
        "\n",
        "Com os dados de teste obtivemos uma perda de  0.4562  e uma acurácia de 0.8666 ou seja 87% dos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS_FEJG_58gA"
      },
      "source": [
        "###Avaliação do modelo de deep learning\n",
        "\n",
        "Acurácia do modelo nos dados de teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NfQF8yo6JfC"
      },
      "outputs": [],
      "source": [
        "# Avaliar o modelo nos dados de teste\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "# Imprimir a perda e        a acurácia\n",
        "print(\"Perda nos dados de teste: {:.4f}\".format(test_loss))\n",
        "print(\"Acurácia nos dados de teste: {:.2f}%\".format(test_accuracy * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSheqvPV5Qd7"
      },
      "source": [
        "###Execução do modelo treinado em um subconjunto das imagems de teste\n",
        "Idealmente se deseja realizar a inferência sobre todo o conjunto de teste, porém para efeitos de agilidade, executamos apenas em um subconjunto de imagens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwDO3VzhBZNv"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "y_pred = list()\n",
        "y_true = list()\n",
        "class_names = ['Car', 'Truck']\n",
        "\n",
        "# Loop do data generator de teste que contem as imagens\n",
        "for batch in test_generator:\n",
        "\n",
        "    count+=1\n",
        "\n",
        "    # Condição de saída do loop. Só executaremos o modelo em algumas imagens\n",
        "    if count == 2:\n",
        "        break\n",
        "\n",
        "    else:\n",
        "\n",
        "        # Pegando a imagem e o label\n",
        "        images = batch[0]\n",
        "        labels = batch[1]\n",
        "\n",
        "        # Previsão\n",
        "        predictions = model.predict(images)\n",
        "\n",
        "        # Visualização da imagem\n",
        "        for i in range(len(images)):\n",
        "\n",
        "            image = images[i]\n",
        "            label = labels[i]\n",
        "            prediction = predictions[i]\n",
        "\n",
        "            # Converte o array de previsão para visualizar a classe e a probabilidade\n",
        "            predicted_class = np.argmax(prediction)\n",
        "            probability = prediction[predicted_class]\n",
        "            label = class_names[int(label)]\n",
        "            y_true.append(label)\n",
        "\n",
        "            # Faz o DE-PARA da probabilidade com o tipo de classe da previsão\n",
        "            class_name = 'Car' if prediction >= 0.5 else 'Truck'\n",
        "            y_pred.append(class_name)\n",
        "\n",
        "            # Configura a saída das imagens que serão visualizadas\n",
        "            plt.imshow(images[i])\n",
        "            plt.axis('Off')\n",
        "            plt.show()\n",
        "\n",
        "            # Imprime os resultados da classificação das images\n",
        "            print(\"Label: \", label)\n",
        "            print(\"Previsão: \", class_name)\n",
        "            print(\"Probabilidade: \", probability)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1m6hKXB5Bt7i"
      },
      "outputs": [],
      "source": [
        "print(y_pred)\n",
        "print(y_true)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8-rjuck5Wfk"
      },
      "outputs": [],
      "source": [
        "\n",
        "def test_model(model, test_generator):\n",
        "    count = 0\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    class_names = ['Car', 'Truck']\n",
        "    contador = 1\n",
        "\n",
        "\n",
        "    # Loop do data generator de teste que contem as imagens\n",
        "    for batch in test_generator:\n",
        "        # Pegando a imagem e o label\n",
        "        images = batch[0]\n",
        "        labels = batch[1]\n",
        "\n",
        "        # Previsão\n",
        "        predictions = model.predict(images)\n",
        "\n",
        "        # Visualização da imagem\n",
        "        for i in range(len(images)):\n",
        "\n",
        "            imagem = images[i]\n",
        "            label = labels[i]\n",
        "            prediction = predictions[i]\n",
        "\n",
        "            # Converte o array de previsão para visualizar a classe e a probabilidade\n",
        "            predicted_class = np.argmax(prediction)\n",
        "            probability = prediction[predicted_class]\n",
        "            label = class_names[int(label)]\n",
        "            y_true.append(label)\n",
        "\n",
        "            # Faz o DE-PARA da probabilidade com o tipo de classe da previsão\n",
        "            class_name = 'Truck' if prediction >= 0.5 else 'Car'\n",
        "            y_pred.append(class_name)\n",
        "\n",
        "            # Configura a saída das imagens que serão visualizadas\n",
        "            plt.imshow(imagem)\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "            # Imprime os resultados da classificação das imagens\n",
        "            print(\"Label: \", label)\n",
        "            print(\"Previsão: \", class_name)\n",
        "            print(\"Probabilidade: \", probability)\n",
        "            print('Número da Imagem: ', contador)\n",
        "            contador += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Chamar a função para testar o modelo\n",
        "test_model(model, test_generator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeVQEqpNAYC7"
      },
      "outputs": [],
      "source": [
        "print(y_pred.value_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY9zrYVt6oVJ"
      },
      "source": [
        "### Visualização de métricas da avaliação do modelo\n",
        "\n",
        "Métricas de performance do modelo no subconjunto das imagens de teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TT66iTKU7WrM"
      },
      "outputs": [],
      "source": [
        "accuracy = skm.accuracy_score(y_true, y_pred)\n",
        "precision = skm.precision_score(y_true, y_pred, average='weighted')\n",
        "recall = skm.recall_score(y_true, y_pred, average='weighted')\n",
        "f1score = skm.f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"Precision: \", precision)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"F1 Score: \", f1score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsKVsNOE6qLl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Fazer as previsões no subconjunto de imagens de teste\n",
        "y_pred = model.predict(test_generator)\n",
        "\n",
        "y_pred = np.argmax(y_pred, axis=1)  # Converte as previsões para as classes preditas\n",
        "\n",
        "# Obter os rótulos verdadeiros do subconjunto de imagens de teste\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Calcular a matriz de confusão\n",
        "confusion = confusion_matrix(y_true, y_pred)\n",
        "class_names = ['Car', 'Truck']\n",
        "\n",
        "# Calcular as métricas de classificação (precisão, recall, F1-score)\n",
        "classification = classification_report(y_true, y_pred, target_names=class_names)\n",
        "\n",
        "# Imprimir a matriz de confusão e as métricas de classificação\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(confusion)\n",
        "print(\"\\nMétricas de Classificação:\")\n",
        "print(classification)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rZcMx0jLk56"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Fazer as previsões no subconjunto de imagens de teste\n",
        "y_pred = model.predict(test_generator)\n",
        "\n",
        "# Converter as previsões para as classes preditas\n",
        "#y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Aplicar a regra de atribuição de 0 ou 1\n",
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] < 0.5:\n",
        "        y_pred[i] = 0\n",
        "    else:\n",
        "        y_pred[i] = 1\n",
        "\n",
        "# Obter os rótulos verdadeiros do subconjunto de imagens de teste\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Calcular a matriz de confusão\n",
        "confusion = confusion_matrix(y_true, y_pred)\n",
        "class_names = ['Car', 'Truck']\n",
        "\n",
        "# Calcular as métricas de classificação (precisão, recall, F1-score)\n",
        "classification = classification_report(y_true, y_pred, target_names=class_names)\n",
        "\n",
        "# Imprimir a matriz de confusão e as métricas de classificação\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(confusion)\n",
        "print(\"\\nMétricas de Classificação:\")\n",
        "print(classification)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HOPphbqDtbg"
      },
      "outputs": [],
      "source": [
        "set(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0iNiAFZ8P6x"
      },
      "source": [
        "Matriz de confusão para identificar onde o modelo de deep learning acertou e errou na classificação do subconjunto de imagens de teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmaDsFyd8Oqn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Fazer as previsões no subconjunto de imagens de teste\n",
        "y_pred = model.predict(test_generator)\n",
        "#y_pred = np.argmax(y_pred, axis=1)  # Converte as previsões para as classes preditas\n",
        "\n",
        "# Aplicar a regra de atribuição de 0 ou 1\n",
        "for i in range(len(y_pred)):\n",
        "    if y_pred[i] < 0.5:\n",
        "        y_pred[i] = 0\n",
        "    else:\n",
        "        y_pred[i] = 1\n",
        "# Obter os rótulos verdadeiros do subconjunto de imagens de teste\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Calcular a matriz de confusão\n",
        "confusion = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Criar um heatmap da matriz de confusão\n",
        "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "\n",
        "# Definir rótulos dos eixos\n",
        "plt.xlabel('Classe Predita')\n",
        "plt.ylabel('Classe Verdadeira')\n",
        "\n",
        "# Definir título do gráfico\n",
        "plt.title('Matriz de Confusão')\n",
        "\n",
        "# Exibir o gráfico\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PW5DoJA4rkE"
      },
      "source": [
        "###Exportação do modelo de deep learning para posterior uso\n",
        "\n",
        "Salvando o modelo de deep learning que foi treinado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4oeEAFZ7pVl"
      },
      "outputs": [],
      "source": [
        "# obtendo a data e hora atual\n",
        "now = datetime.now()\n",
        "\n",
        "# Definição do formato\n",
        "format = '%Y-%m-%dT%H%M'\n",
        "\n",
        "# Converter a data e hora em uma string com o formato especificado\n",
        "formatted_datetime = now.strftime(format)\n",
        "\n",
        "path_model = 'mvp/trained_models'\n",
        "\n",
        "name_model = 'trained_model_' + formatted_datetime + '.h5'\n",
        "\n",
        "# salvando o modelo\n",
        "model.save(\"%s/%s\" % (path_model, name_model))\n",
        "print(\"Modelo salvo com o nome: \", name_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84sZSQ6I87a8"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "y_pred = list()\n",
        "y_true = list()\n",
        "class_names = ['Car', 'Truck']\n",
        "Imagem=0\n",
        "# Loop do data generator de teste que contem as imagens\n",
        "for batch in test_generator:\n",
        "\n",
        "    count+=1\n",
        "\n",
        "    # Condição de saída do loop. Só executaremos o modelo em algumas imagens\n",
        "    if count == 2:\n",
        "        break\n",
        "\n",
        "    else:\n",
        "\n",
        "        # Pegando a imagem e o label\n",
        "        images = batch[0]\n",
        "        labels = batch[1]\n",
        "\n",
        "        # Previsão\n",
        "        predictions = loaded_model.predict(images)\n",
        "\n",
        "        # Visualização da imagem\n",
        "        for i in range(len(images)):\n",
        "            Imagem +=1\n",
        "            image = images[i]\n",
        "            label = labels[i]\n",
        "            prediction = predictions[i]\n",
        "\n",
        "            # Converte o array de previsão para visualizar a classe e a probabilidade\n",
        "            predicted_class = np.argmax(prediction)\n",
        "            probability = prediction[predicted_class]\n",
        "            label = class_names[int(label)]\n",
        "            y_true.append(label)\n",
        "\n",
        "            # Faz o DE-PARA da probabilidade com o tipo de classe da previsão\n",
        "            class_name = 'Car' if prediction >= 0.5 else 'Truck'\n",
        "            y_pred.append(class_name)\n",
        "\n",
        "            # Configura a saída das imagens que serão visualizadas\n",
        "            plt.imshow(images[i])\n",
        "            plt.axis('Off')\n",
        "            plt.show()\n",
        "\n",
        "            # Imprime os resultados da classificação das images\n",
        "            print(\"Label: \", label)\n",
        "            print(\"Previsão: \", class_name)\n",
        "            print(\"Probabilidade: \", probability)\n",
        "            print(\"Imagem: \", Imagem)"
      ]
    }
  ]
}